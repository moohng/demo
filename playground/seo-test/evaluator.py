import asyncio
import base64
import json
import os
from openai import OpenAI
from data_manager import DataManager
from dotenv import load_dotenv

load_dotenv()

# æ”¯æŒå¤šç§AIæ¨¡å‹
# å¯é€‰: openai, gemini
AI_PROVIDER = os.getenv("AI_PROVIDER", "gemini").lower()

if AI_PROVIDER == "openai":
    # OpenAI GPT-4 Vision
    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY")
    )
    MODEL_NAME = "gpt-4o"  # æˆ– gpt-4-vision-preview
elif AI_PROVIDER == "gemini":
    # Google Gemini
    import google.generativeai as genai
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    MODEL_NAME = "gemini-2.5-flash"  # æˆ– gemini-1.5-pro
else:
    raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {AI_PROVIDER}ï¼Œè¯·ä½¿ç”¨ openai æˆ– gemini")

print(f"âœ“ ä½¿ç”¨AIæ¨¡å‹: {AI_PROVIDER} - {MODEL_NAME}")

EVAL_PROMPT = """
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æœç´¢å¼•æ“è¯„æµ‹ä¸“å®¶ã€‚

ç°åœ¨ç»™ä½ ä¸€å¼ æœç´¢ç»“æœé¡µæˆªå›¾ï¼Œè¯·ä½ ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯„åˆ†ï¼š

1. **ç²¾å‡†åº¦å¾—åˆ†ï¼ˆ0-10ï¼‰**  
   - æœç´¢ç»“æœæ˜¯å¦ä¸å…³é”®è¯å¼ºç›¸å…³  
   - æ˜¯å¦å‡ºç°æ— å…³å†…å®¹ã€æ ‡é¢˜å…šã€å†…å®¹å†œåœº  
   - ç»“æœçš„æƒå¨æ€§å’Œå¯ä¿¡åº¦

2. **å¹¿å‘Šå æ¯”å¾—åˆ†ï¼ˆ0-10ï¼‰**  
   - å¹¿å‘Šè¶Šå¤šå¾—åˆ†è¶Šä½  
   - åŒ…æ‹¬ï¼šé¡¶éƒ¨å¹¿å‘Šã€ä¿¡æ¯æµå¹¿å‘Šã€å³ä¾§å¹¿å‘Šã€æ¨å¹¿é“¾æ¥  
   - å¹¿å‘Šä¸å†…å®¹çš„åŒºåˆ†åº¦

3. **é¡µé¢è´¨é‡å¾—åˆ†ï¼ˆ0-10ï¼‰**  
   - é¡µé¢å¸ƒå±€æ˜¯å¦æ¸…æ™°  
   - ä¿¡æ¯å¯†åº¦æ˜¯å¦åˆç†  
   - æ˜¯å¦æœ‰å¹²æ‰°å…ƒç´ ï¼ˆå¼¹çª—ã€è¯±å¯¼ç‚¹å‡»ç­‰ï¼‰

4. **ç”¨æˆ·ä½“éªŒå¾—åˆ†ï¼ˆ0-10ï¼‰**  
   - æœç´¢ç»“æœçš„å¯è¯»æ€§  
   - å…³é”®ä¿¡æ¯æ˜¯å¦çªå‡º  
   - æ•´ä½“è§†è§‰ä½“éªŒ

5. **ç®€è¦è¯„ä»·**ï¼ˆ100å­—ä»¥å†…ï¼‰  
   - æ€»ç»“è¯¥æœç´¢å¼•æ“åœ¨æ­¤å…³é”®è¯ä¸‹çš„è¡¨ç°  
   - æŒ‡å‡ºä¸»è¦ä¼˜ç‚¹å’Œä¸è¶³

è¯·è¿”å›JSONæ ¼å¼ï¼š
{
  "accuracy_score": x,
  "ad_score": x,
  "quality_score": x,
  "ux_score": x,
  "total_score": x,
  "comment": "..."
}

æ³¨æ„ï¼štotal_score = (accuracy_score + ad_score + quality_score + ux_score) / 4
"""


def evaluate_image_openai(image_path, keyword, engine):
    """ä½¿ç”¨OpenAI GPT-4 Visionè¯„æµ‹"""
    with open(image_path, "rb") as f:
        img_bytes = f.read()

    result = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": EVAL_PROMPT},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"æœç´¢å¼•æ“ï¼š{engine}\nå…³é”®è¯ï¼š{keyword}"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64.b64encode(img_bytes).decode()}"
                        }
                    }
                ]
            }
        ],
        temperature=0.3,
        max_tokens=500
    )
    
    return result.choices[0].message.content


def evaluate_image_gemini(image_path, keyword, engine):
    """ä½¿ç”¨Google Geminiè¯„æµ‹"""
    import PIL.Image
    
    # åŠ è½½å›¾ç‰‡
    img = PIL.Image.open(image_path)
    
    # åˆ›å»ºæ¨¡å‹
    model = genai.GenerativeModel(MODEL_NAME)
    
    # ç”Ÿæˆè¯„æµ‹
    prompt = f"{EVAL_PROMPT}\n\næœç´¢å¼•æ“ï¼š{engine}\nå…³é”®è¯ï¼š{keyword}"
    result = model.generate_content([prompt, img])
    
    return result.text


def evaluate_image(image_path, keyword, engine):
    """ä½¿ç”¨AIè¯„æµ‹å•å¼ æˆªå›¾"""
    try:
        # æ ¹æ®æä¾›å•†é€‰æ‹©è¯„æµ‹å‡½æ•°
        if AI_PROVIDER == "openai":
            content = evaluate_image_openai(image_path, keyword, engine)
        elif AI_PROVIDER == "gemini":
            content = evaluate_image_gemini(image_path, keyword, engine)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {AI_PROVIDER}")
        
        # å°è¯•è§£æJSON
        try:
            # æå–JSONéƒ¨åˆ†ï¼ˆæœ‰æ—¶AIä¼šåœ¨JSONå‰åæ·»åŠ è¯´æ˜æ–‡å­—ï¼‰
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            evaluation = json.loads(content)
            return evaluation
        except json.JSONDecodeError:
            print(f"âš ï¸ JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹ï¼š{content}")
            return {
                "accuracy_score": 0,
                "ad_score": 0,
                "quality_score": 0,
                "ux_score": 0,
                "total_score": 0,
                "comment": f"è¯„æµ‹å¤±è´¥ï¼š{content[:100]}"
            }
    
    except Exception as e:
        print(f"âœ— è¯„æµ‹å¤±è´¥ï¼š{str(e)}")
        return {
            "accuracy_score": 0,
            "ad_score": 0,
            "quality_score": 0,
            "ux_score": 0,
            "total_score": 0,
            "comment": f"è¯„æµ‹å¼‚å¸¸ï¼š{str(e)}"
        }


async def run_evaluation():
    """è¿è¡ŒAIè¯„æµ‹"""
    data_manager = DataManager()
    
    # è·å–æœªè¯„æµ‹çš„æˆåŠŸæµ‹è¯•
    unevaluated = data_manager.get_unevaluated_tests()
    
    if not unevaluated:
        print("âœ“ æ²¡æœ‰éœ€è¦è¯„æµ‹çš„æ•°æ®")
        data_manager.print_summary()
        return
    
    print(f"\nğŸ¤– å¼€å§‹AIè¯„æµ‹ï¼Œå…± {len(unevaluated)} ä¸ªé¡¹ç›®")
    print("="*50)
    
    success_count = 0
    failed_count = 0
    
    for i, record in enumerate(unevaluated, 1):
        engine = record["engine"]
        keyword = record["keyword"]
        image_path = record["screenshot_path"]
        
        print(f"\nè¿›åº¦ï¼š{i}/{len(unevaluated)}")
        print(f"ğŸ” è¯„æµ‹ï¼š{engine} / {keyword}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
            failed_count += 1
            continue
        
        # æ‰§è¡Œè¯„æµ‹
        evaluation = evaluate_image(image_path, keyword, engine)
        
        # æ›´æ–°æ•°æ®
        data_manager.update_evaluation(engine, keyword, evaluation)
        
        # è¾“å‡ºç»“æœ
        if evaluation.get("total_score", 0) > 0:
            print(f"âœ“ è¯„æµ‹å®Œæˆ")
            print(f"  - ç²¾å‡†åº¦ï¼š{evaluation.get('accuracy_score', 0)}/10")
            print(f"  - å¹¿å‘Šå æ¯”ï¼š{evaluation.get('ad_score', 0)}/10")
            print(f"  - é¡µé¢è´¨é‡ï¼š{evaluation.get('quality_score', 0)}/10")
            print(f"  - ç”¨æˆ·ä½“éªŒï¼š{evaluation.get('ux_score', 0)}/10")
            print(f"  - æ€»åˆ†ï¼š{evaluation.get('total_score', 0):.2f}/10")
            success_count += 1
        else:
            print(f"âœ— è¯„æµ‹å¤±è´¥")
            failed_count += 1
        
        # æ¯æ¬¡è¯„æµ‹åä¿å­˜æ•°æ®ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±ï¼‰
        if i % 5 == 0:
            data_manager.save_data()
            print(f"\nğŸ’¾ å·²ä¿å­˜è¿›åº¦ï¼ˆ{i}/{len(unevaluated)}ï¼‰")
        
        # é¿å…APIé™æµ
        await asyncio.sleep(1)
    
    # æœ€ç»ˆä¿å­˜
    data_manager.save_data()
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "="*50)
    print("ğŸ“Š è¯„æµ‹ç»“æœæ‘˜è¦")
    print("="*50)
    print(f"âœ“ æˆåŠŸï¼š{success_count}")
    print(f"âœ— å¤±è´¥ï¼š{failed_count}")
    print("="*50)
    
    data_manager.print_summary()


async def main():
    await run_evaluation()


if __name__ == "__main__":
    asyncio.run(main())